# Environment Configuration Template

# Server Configuration
PORT=3000
NODE_ENV=development

# Database Configuration
# Format: postgresql://username:password@host:port/database_name
# Example: postgresql://postgres:mypassword@localhost:5432/ai_chatbot_db
DATABASE_URL=postgresql://<username>:<password>@localhost:5432/<database_name>

# Database SSL (set to true for production databases like Heroku, AWS RDS, etc.)
DB_SSL=false

# Redis Configuration (for caching)
# Development: No password required (localhost only)
# Production: Set REDIS_PASSWORD for security
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0

# OpenAI Configuration
# Required for chat completions and semantic search (embeddings)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here

# JWT Configuration (change these in production!)
JWT_SECRET=your-super-secret-jwt-key-change-this-in-production
JWT_EXPIRES_IN=1h
REFRESH_TOKEN_SECRET=your-super-secret-refresh-token-key-change-this
REFRESH_TOKEN_EXPIRES_IN=7d

# CORS Configuration (comma-separated list of allowed origins)
CORS_ORIGINS=http://localhost:5173,http://localhost:3000

# Logging
LOG_LEVEL=info

# Feature Flags
# Disable conversation context (use only current message)
DISABLE_CONTEXT=false

# Enable semantic context (use embeddings for intelligent context building)
# Requires OPENAI_API_KEY to be set
# When enabled, combines recent messages with semantically relevant older messages
USE_SEMANTIC_CONTEXT=false

# Long Term Memory Configuration
# Enable Long Term Memory system (remembers user facts, preferences, and conversation history)
# Requires Redis (for user profiles) and PostgreSQL with pgvector extension (for events)
LTM_ENABLED=true

# Redis TTL for user profiles (in seconds)
# Default: 604800 (7 days) - profiles expire after 7 days of inactivity
LTM_REDIS_TTL=604800

# OpenAI model for memory extraction (Meta-LLM)
# Recommended: gpt-4o-mini (cost-effective, consistent JSON output)
# Alternative: gpt-4o, gpt-3.5-turbo
LTM_META_MODEL=gpt-4o-mini

# Maximum number of relevant events to retrieve for context building
# Default: 100 - balances context richness with token usage
LTM_MAX_EVENTS=100

# Delay before starting background memory analysis (milliseconds)
# Default: 2000 (2 seconds) - allows message to be sent first
LTM_BACKGROUND_DELAY=2000

# Cloudinary Configuration (for file/image uploads)
# Sign up for free at: https://cloudinary.com
# Get your credentials from: https://cloudinary.com/console
CLOUDINARY_NAME=your-cloudinary-cloud-name
CLOUDINARY_API_KEY=your-cloudinary-api-key
CLOUDINARY_SECRET_KEY=your-cloudinary-api-secret

# File Upload Configuration
MAX_FILE_SIZE=10485760
ALLOWED_FILE_TYPES=image/jpeg,image/png,image/gif,image/webp,application/pdf,text/plain,application/msword,application/vnd.openxmlformats-officedocument.wordprocessingml.document
